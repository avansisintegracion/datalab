<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Cristian, Mikael">
  <meta name="dcterms.date" content="2017-05-23">
  <title>Partage de connaissance</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.19.1/vis.min.js"></script>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.19.1/vis.min.css" rel="stylesheet" />
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title">Partage de connaissance</h1>
  <p class="subtitle">Compétition kaggle 🐟</p>
  <p class="author">Cristian, Mikael</p>
  <p class="date">2017-05-23</p>
</section>

<section><section id="the-competition-and-the-data" class="titleslide slide level1"><h1>1. The competition and the data</h1></section><section id="starting-point" class="slide level2" data-background="https://media.giphy.com/media/WfNIOjdnCh212/giphy.gif?response_id=591d519f2c191af3c3ffbedd">
<h2><font color="white">Starting point </font></h2>
<p><font color="white">In the Western and Central Pacific, 60% of the world’s tuna is caught illegally, a threat to marine ecosystem.</font></p>
</section><section id="goal-of-the-competition" class="slide level2">
<h2>Goal of the competition</h2>
<p>Automate fish detection on pictures from fishing boats. (with machine learning)</p>
<video controls="controls" poster="https://kaggle2.blob.core.windows.net/competitions/kaggle/5568/media/TNC-poster-640x360.png" width="640" height="360">
<source src="https://kaggle2.blob.core.windows.net/competitions/kaggle/5568/media/TNC.mp4" type="video/mp4"> Your browser does not support the video tag.
</video>
</section><section id="images-classes" class="slide level2">
<h2>Images classes</h2>
<figure>
<img src="images/fish_classes.jpeg" class="plain" />
</figure>
</section><section id="data" class="slide level2">
<h2>Data</h2>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th>Number of photos</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Train</td>
<td>3777</td>
</tr>
<tr class="even">
<td>Test stage 1</td>
<td>1000</td>
</tr>
<tr class="odd">
<td>Test stage 2</td>
<td>12000</td>
</tr>
</tbody>
</table>
</section><section id="class-distribution" class="slide level2">
<h2>Class distribution</h2>
<figure>
<img src="images/Distribution.png" class="plain" style="width:50.0%" />
</figure>
</section><section id="image-sizes" class="slide level2">
<h2>Image sizes</h2>
<figure>
<img src="images/Images_sizes.png" class="plain" style="width:50.0%" />
</figure>
</section><section id="preliminary-observations" class="slide level2">
<h2>Preliminary observations</h2>
<ul>
<li>Pictures from video sequences</li>
<li>Limited number of boats in training set</li>
<li>Day/night pictures</li>
<li>Multiple fishes per picture</li>
<li>Train set labelling errors</li>
</ul>
</section><section id="important-dates" class="slide level2">
<h2>Important dates</h2>
<div id="visualization">

</div>
<script type="text/javascript">
  // DOM element where the Timeline will be attached
  var container = document.getElementById('visualization');

  // Create a DataSet (allows two way data-binding)
  var items = new vis.DataSet([
    {id: 1, content: '<span style="color:#97B0F8;"> 14 Nov: </span> Competition start', start: '2016-11-14'},
    {id: 2, content: '<span style="color:#97B0F8;"> 13 Jan: </span> We start 🎉', start: '2017-01-13'},
    {id: 3, content: '<span style="color:#97B0F8;"> 06 April: </span> End Stage 1', start: '2017-04-06'},
    {id: 4, content: '<span style="color:#97B0F8;"> 13 April: </span> End Stage 2', start: '2017-04-13'}
  ]);

  // Configuration for the Timeline
  var options = {};

  // Create a Timeline
  var timeline = new vis.Timeline(container, items, options);
</script>
</section></section>
<section><section id="computer-vision-based-approach" class="titleslide slide level1"><h1>2. Computer vision based approach</h1></section><section id="extract-features" class="slide level2">
<h2>Extract features</h2>
<figure>
<img src="images/bag_of_features_1.png" class="plain" />
</figure>
</section><section id="combine-features-and-train-a-model" class="slide level2">
<h2>Combine features and train a model</h2>
<figure>
<img src="images/bag_of_features_2.png" class="plain" />
</figure>
</section><section id="analyze-the-results" class="slide level2">
<h2>Analyze the results</h2>
<figure>
<img src="images/results_I_bag_of_features.png" class="plain" />
</figure>
</section><section id="remove-background-information" class="slide level2">
<h2>Remove background information</h2>
<figure>
<img src="images/interest_point_detection.png" class="plain" style="width:70.0%" />
</figure>
</section><section id="take-into-account-the-cameras" class="slide level2">
<h2>Take into account the cameras</h2>
<p><img src="images/img_00020.jpg" class="plain" style="width:30.0%" /> <img src="images/img_00029.jpg" class="plain" style="width:30.0%" /> <img src="images/img_00038.jpg" class="plain" style="width:30.0%" /></p>
<p>Developped a Custom splitting</p>
</section><section id="final-scoring" class="slide level2">
<h2>Final scoring</h2>
<figure>
<img src="images/scores_xgboost.svg" class="plain" style="width:71.0%" />
</figure>
<ul>
<li>Difficult to engineer the features</li>
<li>Model robust for prediction on new data</li>
<li>Top 1, private leaderboard : 1.06</li>
</ul>
</section></section>
<section><section id="a-methodological-break" class="titleslide slide level1"><h1>3. A methodological break</h1></section><section id="cookiecutter" class="slide level2">
<h2>Cookiecutter</h2>
<pre class="txt"><code>├── LICENSE
├── Makefile           &lt;- Makefile with commands like &#39;make data&#39; or &#39;make train&#39;
├── README.md          &lt;- The top-level README for developers using this project.
├── data
│   ├── external       &lt;- Data from third party sources.
│   ├── interim        &lt;- Intermediate data that has been transformed.
│   ├── processed      &lt;- The final, canonical data sets for modeling.
│   └── raw            &lt;- The original, immutable data dump.
│
├── docs               &lt;- A default Sphinx project; see sphinx-doc.org for details
│
├── models             &lt;- Trained and serialized models, model predictions, or model summaries
│
├── notebooks          &lt;- Jupyter notebooks. Naming convention is a number (for ordering),
│                         the creator s initials, and a short &#39;-&#39; delimited description, e.g.
│                         &#39;1.0-jqp-initial-data-exploration&#39;.
│
├── references         &lt;- Data dictionaries, manuals, and all other explanatory materials.
│
├── reports            &lt;- Generated analysis as HTML, PDF, LaTeX, etc.
│   └── figures        &lt;- Generated graphics and figures to be used in reporting
│
├── requirements.txt   &lt;- The requirements file for reproducing the analysis environment, e.g.
│                         generated with &#39;pip freeze &gt; requirements.txt&#39;
│
├── src                &lt;- Source code for use in this project.
│   ├── __init__.py    &lt;- Makes src a Python module
│   │
│   ├── data           &lt;- Scripts to download or generate data
│   │   └── make_dataset.py
│   │
│   ├── features       &lt;- Scripts to turn raw data into features for modeling
│   │   └── build_features.py
│   │
│   ├── models         &lt;- Scripts to train models and then use trained models to make
│   │   │                 predictions
│   │   ├── predict_model.py
│   │   └── train_model.py
│   │
│   └── visualization  &lt;- Scripts to create exploratory and results oriented visualizations
│       └── visualize.py
│
└── tox.ini            &lt;- tox file with settings for running tox; see tox.testrun.org
</code></pre>
<p>Note : Cookiecutter is based on jinja2...</p>
<p><a href="https://drivendata.github.io/cookiecutter-data-science/">Source</a></p>
</section><section id="data-abstraction-layer" class="slide level2">
<h2>Data abstraction layer</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">class</span> ProjFolder(objdict):
    <span class="co">&quot;&quot;&quot;</span>
<span class="co">    A class to define project&#39;s subfolders for easy access.</span>
<span class="co">    &quot;&quot;&quot;</span>
    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):
        <span class="co"># level data</span>
        <span class="va">self</span>.datafolder <span class="op">=</span> op.join(ROOTFOLDER, <span class="st">&#39;data&#39;</span>)
        <span class="cf">for</span> subfol <span class="kw">in</span> [<span class="st">&#39;external&#39;</span>, <span class="st">&#39;interim&#39;</span>, <span class="st">&#39;processed&#39;</span>, <span class="st">&#39;raw&#39;</span>]:
            <span class="bu">setattr</span>(<span class="va">self</span>,
                    <span class="st">&#39;data_&#39;</span> <span class="op">+</span> subfol,
                    op.join(<span class="va">self</span>.datafolder, subfol))

        <span class="co"># level data external</span>
        <span class="cf">for</span> subfol <span class="kw">in</span> [<span class="st">&#39;annos&#39;</span>, <span class="st">&#39;rotate_crop&#39;</span>]:
            <span class="bu">setattr</span>(<span class="va">self</span>,
                    <span class="st">&#39;data_external_&#39;</span> <span class="op">+</span> subfol,
                    op.join(<span class="va">self</span>.data_external, subfol))

        <span class="co"># level data interim</span>
        <span class="cf">for</span> subfol <span class="kw">in</span> [<span class="st">&#39;train&#39;</span>, <span class="st">&#39;test&#39;</span>]:
            <span class="bu">setattr</span>(<span class="va">self</span>,
                    <span class="st">&#39;data_interim_&#39;</span> <span class="op">+</span> subfol,
                    op.join(<span class="va">self</span>.data_interim, subfol))

        <span class="cf">for</span> subfol <span class="kw">in</span> [<span class="st">&#39;crop&#39;</span>, <span class="st">&#39;generated&#39;</span>, <span class="st">&#39;rotatecrop&#39;</span>, <span class="st">&#39;raw&#39;</span>]:
            <span class="bu">setattr</span>(<span class="va">self</span>,
                    <span class="st">&#39;data_interim_train_&#39;</span> <span class="op">+</span> subfol,
                    op.join(<span class="va">self</span>.data_interim_train, subfol))

        <span class="cf">for</span> subfol <span class="kw">in</span> [<span class="st">&#39;train&#39;</span>, <span class="st">&#39;val&#39;</span>]:
            <span class="bu">setattr</span>(<span class="va">self</span>,
                    <span class="st">&#39;data_interim_train_crop_&#39;</span> <span class="op">+</span> subfol,
                    op.join(<span class="va">self</span>.data_interim_train_crop, subfol))

        <span class="cf">for</span> subfol <span class="kw">in</span> [<span class="st">&#39;train&#39;</span>, <span class="st">&#39;val&#39;</span>]:
            <span class="bu">setattr</span>(<span class="va">self</span>,
                    <span class="st">&#39;data_interim_train_rotatecrop_&#39;</span> <span class="op">+</span> subfol,
                    op.join(<span class="va">self</span>.data_interim_train_rotatecrop, subfol))

        <span class="co"># level data processed</span>
        <span class="co"># for subfol in []:</span>
        <span class="co">#     setattr(self,</span>
        <span class="co">#             &#39;data_processed_&#39; + subfol,</span>
        <span class="co">#             op.join(self.data_processed, subfol))</span>

        <span class="co"># level data raw</span>
        <span class="cf">for</span> subfol <span class="kw">in</span> [<span class="st">&#39;train&#39;</span>, <span class="st">&#39;test&#39;</span>, <span class="st">&#39;test2&#39;</span>]:
            <span class="bu">setattr</span>(<span class="va">self</span>,
                    <span class="st">&#39;data_raw_&#39;</span> <span class="op">+</span> subfol,
                    op.join(<span class="va">self</span>.data_raw, subfol))

    <span class="kw">def</span> make_folder(<span class="va">self</span>):
        <span class="cf">for</span> directory <span class="kw">in</span> <span class="va">self</span>.values():
            <span class="cf">if</span> <span class="kw">not</span> op.exists(directory):
                os.makedirs(directory)</code></pre></div>
</section><section id="data-abstraction-layer-ii" class="slide level2">
<h2>Data abstraction layer II</h2>
<p>Every image had properties saved into json:</p>
<ul>
<li>name</li>
<li>image name</li>
<li>path to raw</li>
<li>path to cropped</li>
<li>fish type</li>
<li>...</li>
</ul>
</section><section id="advantages" class="slide level2">
<h2>Advantages</h2>
<ul>
<li>Stimulates <strong>clear</strong> code file structure</li>
<li>Speed to get folder structure</li>
<li>Pythonic, object oriented</li>
<li>Fast to expand analysis</li>
</ul>
</section><section id="the-break-is-over" class="slide level2">
<h2>The break is over ;)</h2>
</section></section>
<section><section id="deep-learning-approach" class="titleslide slide level1"><h1>4. Deep learning approach</h1></section><section id="bounding-box-regression" class="slide level2">
<h2>Bounding box regression</h2>
<ul>
<li>Fishes Bounding box coordinates shared on <a href="https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/discussion/25902">kaggle forum</a>.</li>
<li>Done using <a href="https://github.com/cvhciKIT/sloth">Sloth</a>.</li>
<li>Coordinates of the bounding box referenced as (<code>x</code>, <code>y</code>, <code>width</code> and <code>height</code>).</li>
</ul>
</section><section id="multiple-fish-per-picture" class="slide level2">
<h2>Multiple fish per picture</h2>
<ul>
<li>Only one bounding box per picture,</li>
<li>No Fish : empty coordinates.</li>
</ul>
</section><section id="image-preprocessing-with-keras" class="slide level2">
<h2>Image preprocessing with keras</h2>
<ul>
<li>Preprocessing with Keras (<a href="https://keras.io/preprocessing/image/">ImageDataGenerator</a>)
<ul>
<li>Rescale <code>[0:255] -&gt; [0.:1.]</code> (InceptionV3 graph operates on floating point values)</li>
</ul></li>
<li>Preprocessing generator <code>flow_from_directory</code>:
<ul>
<li>Read images form a directory.</li>
<li>Assign class for each subdirectory</li>
<li>Generates batches of augmented/normalized data</li>
<li>Yields batches indefinitely, in an infinite loop.</li>
</ul></li>
</ul>
</section><section id="training" class="slide level2">
<h2>Training</h2>
<ul>
<li>Keras also provides a method to train images by <strong>batches</strong> (<code>fit_generator</code>)
<ul>
<li>reduce memory utilization.</li>
<li>image preprocessing to be done in parallel of training process</li>
<li>the input must be transformed into a generator</li>
</ul></li>
</ul>
</section><section class="slide level2">

<h3 id="train-the-model-by-batch">Train the model by batch</h3>
<ul>
<li>The generator contains:
<ul>
<li>The image generator</li>
<li>The bounding box coordinates generator</li>
<li>The Fish/NoFish label</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">(X_train, y_label)
([batch_size, img_width, img_height, <span class="dv">3</span>], [[batch_size, <span class="dv">4</span>] [batch_size, <span class="dv">1</span>]])</code></pre></div>
<ul>
<li>itertools: <a href="https://docs.python.org/2/library/itertools.html#itertools.cycle">cylce</a>, <a href="https://docs.python.org/2/library/itertools.html#itertools.izip">izip</a></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="op">&gt;&gt;&gt;</span> itertools.cycle(<span class="st">&#39;ABCD&#39;</span>)
A B C D A B C D ...`
<span class="op">&gt;&gt;&gt;</span> itertools.izip(<span class="st">&#39;ABCD&#39;</span>, <span class="st">&#39;xy&#39;</span>)
Ax By`</code></pre></div>
</section><section id="pretrained-model" class="slide level2">
<h2>Pretrained model</h2>
<ul>
<li><p>Pretrained network determine universal features (curves and edges) in its early layers.</p></li>
<li>Pretrained models
<ul>
<li>Complex architecture with huge amount of parameters</li>
<li>Trained on large datasets like the ImageNet, with 1.2M labelled images.</li>
</ul></li>
</ul>
</section><section id="fine-tuning" class="slide level2">
<h2>Fine tuning</h2>
<ul>
<li>Replace last layer it with a new softmax layer with the number of class</li>
</ul>
<figure>
<img src="images/transfer_learning.png" title="opt title" />
</figure>
</section><section id="cropping-results" class="slide level2">
<h2>Cropping results</h2>
<ul>
<li>Objective function: <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean square error</a> of the bounding box coordinates</li>
<li>Results evaluation:
<ul>
<li>Qualitatively:
<ul>
<li>Looking at the results of the photos</li>
</ul></li>
<li>Quantitatively:
<ul>
<li>Leaderboard results</li>
<li><a href="http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">Intersection over Union</a></li>
</ul></li>
</ul></li>
</ul>
</section><section id="some-images-of-the-test-set" class="slide level2">
<h2>Some images of the test set</h2>
<figure>
<img src="images/fish/out.jpg" />
</figure>
</section><section id="intersection-over-union" class="slide level2">
<h2>Intersection over union</h2>
<figure>
<img src="images/histotrain.jpg" class="plain" style="width:50.0%" />
</figure>
<ul>
<li>Model does not on new boats</li>
<li>Only one bounding box photo</li>
</ul>
</section><section id="classification-model" class="slide level2">
<h2>Classification model</h2>
<ul>
<li>Fine tuning using InceptionV3</li>
<li>Image augmentation for prediction:
<ul>
<li>Rescale <code>[0:255] -&gt; [0.:1.]</code></li>
<li>Shear 0.1, zoom, rotation (10), horizontal shift, vertical shift.</li>
<li>Change of seed</li>
<li>Average prediction probabilities</li>
</ul></li>
</ul>
</section><section id="classification-results" class="slide level2">
<h2>Classification results</h2>
<table>
<thead>
<tr class="header">
<th>-</th>
<th>-</th>
<th>Random split</th>
<th>-</th>
<th>-</th>
<th>Boat split</th>
<th>-</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-</td>
<td>Val</td>
<td>Public</td>
<td>Private</td>
<td>Val</td>
<td>Public</td>
<td>Private</td>
</tr>
<tr class="even">
<td>Raw images</td>
<td>0.4</td>
<td>1.02</td>
<td>2.66</td>
<td>0.98</td>
<td>1.3</td>
<td>2.65</td>
</tr>
<tr class="odd">
<td>Cropped images</td>
<td>0.2</td>
<td></td>
<td></td>
<td>0.96</td>
<td>1.41</td>
<td>3.01</td>
</tr>
</tbody>
</table>
</section><section id="with-boat-split" class="slide level2">
<h2>With Boat split</h2>
<p><img src="images/cmInceptionBoatSplit.svg" class="plain" style="width:45.0%" /> <img src="images/pdInceptionBoatSplit.svg" class="plain" style="width:45.0%" /></p>
</section><section id="random-split" class="slide level2">
<h2>Random split</h2>
<p><img src="images/cmInceptionRandomSplit.svg" class="plain" style="width:45.0%" /> <img src="images/pdInceptionRandomSplit.svg" class="plain" style="width:45.0%" /></p>
</section><section id="bonus" class="slide level2">
<h2>Bonus</h2>
<ul>
<li>Special metion to clip
<ul>
<li>We set a maximum and a minimum certainty</li>
<li>Avoids really hard punishment in case we're wrong</li>
<li>Improve our score in public leader board from 1.02 on public leader board to 0.92</li>
</ul></li>
</ul>
</section></section>
<section><section id="elements-of-conclusion" class="titleslide slide level1"><h1>5. Elements of conclusion</h1></section><section id="what-we-learned" class="slide level2">
<h2>What we learned</h2>
<ul>
<li>Working together in an efficient manner</li>
<li>Getting fair results 'easily'</li>
<li>Kaggle organizer can mess things up quite a bit (stage 1/2)</li>
<li>How to work with images and machine learning (computer vision &amp; convnet)</li>
<li>Specificities of the dataset : boat splitting, tiny differences between species...</li>
</ul>
</section><section id="what-the-best-contestants-did" class="slide level2">
<h2>What the best contestants did</h2>
<ul>
<li>Massive ensembling</li>
<li>State-of-the-art object detection (FastRCNN, SSD,...)</li>
<li>Used pretrained models that are hardly available for newcomers (not implemented in current standard libraries)</li>
<li>Spent more time</li>
</ul>
</section><section id="not-sure-if-it-should-be-kept...-or-how-to-organize" class="slide level2">
<h2>Not sure if it should be kept... or how to organize</h2>
<ul>
<li>Image preprocessing can significantly increase the performance of a classification algorithm.</li>
<li>A feature descriptor represents a simplified version of an image by extracting useful information and throwing away extraneous information.</li>
<li>Using feature description increases training speed compared with raw images.</li>
</ul>
</section></section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
              { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
